{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3043695,"sourceType":"datasetVersion","datasetId":1861688}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Named Entity Recognition","metadata":{}},{"cell_type":"code","source":"! pip install seqeval==0.0.10","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:53:29.231032Z","iopub.execute_input":"2024-07-12T13:53:29.231384Z","iopub.status.idle":"2024-07-12T13:53:44.321230Z","shell.execute_reply.started":"2024-07-12T13:53:29.231353Z","shell.execute_reply":"2024-07-12T13:53:44.320117Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting seqeval==0.0.10\n  Downloading seqeval-0.0.10-py3-none-any.whl.metadata (3.4 kB)\nRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from seqeval==0.0.10) (1.26.4)\nRequirement already satisfied: Keras>=2.2.4 in /opt/conda/lib/python3.10/site-packages (from seqeval==0.0.10) (3.3.3)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from Keras>=2.2.4->seqeval==0.0.10) (1.4.0)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from Keras>=2.2.4->seqeval==0.0.10) (13.7.0)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from Keras>=2.2.4->seqeval==0.0.10) (0.0.8)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from Keras>=2.2.4->seqeval==0.0.10) (3.10.0)\nRequirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from Keras>=2.2.4->seqeval==0.0.10) (0.11.0)\nRequirement already satisfied: ml-dtypes in /opt/conda/lib/python3.10/site-packages (from Keras>=2.2.4->seqeval==0.0.10) (0.2.0)\nRequirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from optree->Keras>=2.2.4->seqeval==0.0.10) (4.9.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->Keras>=2.2.4->seqeval==0.0.10) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->Keras>=2.2.4->seqeval==0.0.10) (2.17.2)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->Keras>=2.2.4->seqeval==0.0.10) (0.1.2)\nDownloading seqeval-0.0.10-py3-none-any.whl (7.5 kB)\nInstalling collected packages: seqeval\nSuccessfully installed seqeval-0.0.10\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom seqeval.metrics import classification_report, f1_score\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-12T13:53:44.323972Z","iopub.execute_input":"2024-07-12T13:53:44.324727Z","iopub.status.idle":"2024-07-12T13:53:45.341211Z","shell.execute_reply.started":"2024-07-12T13:53:44.324687Z","shell.execute_reply":"2024-07-12T13:53:45.340129Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Read and Preproc data","metadata":{}},{"cell_type":"code","source":"def loading_data(data_path):\n    \n    data = pd.read_csv(data_path)\n    \n    data.dropna(inplace=True)\n    print(\"Number of rows : \",data.shape[0],\" and the number of columns : \",data.shape[1])\n    \n    return data","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:53:45.342514Z","iopub.execute_input":"2024-07-12T13:53:45.342993Z","iopub.status.idle":"2024-07-12T13:53:45.348527Z","shell.execute_reply.started":"2024-07-12T13:53:45.342963Z","shell.execute_reply":"2024-07-12T13:53:45.347561Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data = loading_data(\"/kaggle/input/named-entity-recognition-ner-corpus/ner.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:53:45.350065Z","iopub.execute_input":"2024-07-12T13:53:45.350412Z","iopub.status.idle":"2024-07-12T13:53:45.869691Z","shell.execute_reply.started":"2024-07-12T13:53:45.350385Z","shell.execute_reply":"2024-07-12T13:53:45.868620Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Number of rows :  47959  and the number of columns :  4\n","output_type":"stream"}]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:53:45.873064Z","iopub.execute_input":"2024-07-12T13:53:45.873507Z","iopub.status.idle":"2024-07-12T13:53:45.896445Z","shell.execute_reply.started":"2024-07-12T13:53:45.873479Z","shell.execute_reply":"2024-07-12T13:53:45.895460Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"    Sentence #                                           Sentence  \\\n0  Sentence: 1  Thousands of demonstrators have marched throug...   \n1  Sentence: 2  Families of soldiers killed in the conflict jo...   \n2  Sentence: 3  They marched from the Houses of Parliament to ...   \n3  Sentence: 4  Police put the number of marchers at 10,000 wh...   \n4  Sentence: 5  The protest comes on the eve of the annual con...   \n\n                                                 POS  \\\n0  ['NNS', 'IN', 'NNS', 'VBP', 'VBN', 'IN', 'NNP'...   \n1  ['NNS', 'IN', 'NNS', 'VBN', 'IN', 'DT', 'NN', ...   \n2  ['PRP', 'VBD', 'IN', 'DT', 'NNS', 'IN', 'NN', ...   \n3  ['NNS', 'VBD', 'DT', 'NN', 'IN', 'NNS', 'IN', ...   \n4  ['DT', 'NN', 'VBZ', 'IN', 'DT', 'NN', 'IN', 'D...   \n\n                                                 Tag  \n0  ['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', '...  \n1  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n2  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n3  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n4  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence #</th>\n      <th>Sentence</th>\n      <th>POS</th>\n      <th>Tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sentence: 1</td>\n      <td>Thousands of demonstrators have marched throug...</td>\n      <td>['NNS', 'IN', 'NNS', 'VBP', 'VBN', 'IN', 'NNP'...</td>\n      <td>['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', '...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sentence: 2</td>\n      <td>Families of soldiers killed in the conflict jo...</td>\n      <td>['NNS', 'IN', 'NNS', 'VBN', 'IN', 'DT', 'NN', ...</td>\n      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Sentence: 3</td>\n      <td>They marched from the Houses of Parliament to ...</td>\n      <td>['PRP', 'VBD', 'IN', 'DT', 'NNS', 'IN', 'NN', ...</td>\n      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Sentence: 4</td>\n      <td>Police put the number of marchers at 10,000 wh...</td>\n      <td>['NNS', 'VBD', 'DT', 'NN', 'IN', 'NNS', 'IN', ...</td>\n      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sentence: 5</td>\n      <td>The protest comes on the eve of the annual con...</td>\n      <td>['DT', 'NN', 'VBZ', 'IN', 'DT', 'NN', 'IN', 'D...</td>\n      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def preproc(data):\n    data['POS'] = data['POS'].apply(lambda x: eval(x))\n    data['Tag'] = data['Tag'].apply(lambda x: eval(x))\n    \n    return data","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:53:45.897549Z","iopub.execute_input":"2024-07-12T13:53:45.897876Z","iopub.status.idle":"2024-07-12T13:53:45.903268Z","shell.execute_reply.started":"2024-07-12T13:53:45.897848Z","shell.execute_reply":"2024-07-12T13:53:45.902271Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data = preproc(data)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:53:45.904485Z","iopub.execute_input":"2024-07-12T13:53:45.904895Z","iopub.status.idle":"2024-07-12T13:53:49.819544Z","shell.execute_reply.started":"2024-07-12T13:53:45.904869Z","shell.execute_reply":"2024-07-12T13:53:49.818687Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:53:49.820647Z","iopub.execute_input":"2024-07-12T13:53:49.820941Z","iopub.status.idle":"2024-07-12T13:53:49.837555Z","shell.execute_reply.started":"2024-07-12T13:53:49.820916Z","shell.execute_reply":"2024-07-12T13:53:49.836587Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"    Sentence #                                           Sentence  \\\n0  Sentence: 1  Thousands of demonstrators have marched throug...   \n1  Sentence: 2  Families of soldiers killed in the conflict jo...   \n2  Sentence: 3  They marched from the Houses of Parliament to ...   \n3  Sentence: 4  Police put the number of marchers at 10,000 wh...   \n4  Sentence: 5  The protest comes on the eve of the annual con...   \n\n                                                 POS  \\\n0  [NNS, IN, NNS, VBP, VBN, IN, NNP, TO, VB, DT, ...   \n1  [NNS, IN, NNS, VBN, IN, DT, NN, VBD, DT, NNS, ...   \n2  [PRP, VBD, IN, DT, NNS, IN, NN, TO, DT, NN, IN...   \n3  [NNS, VBD, DT, NN, IN, NNS, IN, CD, IN, NNS, V...   \n4  [DT, NN, VBZ, IN, DT, NN, IN, DT, JJ, NN, IN, ...   \n\n                                                 Tag  \n0  [O, O, O, O, O, O, B-geo, O, O, O, O, O, B-geo...  \n1  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n2  [O, O, O, O, O, O, O, O, O, O, O, B-geo, I-geo...  \n3      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]  \n4  [O, O, O, O, O, O, O, O, O, O, O, B-geo, O, O,...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence #</th>\n      <th>Sentence</th>\n      <th>POS</th>\n      <th>Tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sentence: 1</td>\n      <td>Thousands of demonstrators have marched throug...</td>\n      <td>[NNS, IN, NNS, VBP, VBN, IN, NNP, TO, VB, DT, ...</td>\n      <td>[O, O, O, O, O, O, B-geo, O, O, O, O, O, B-geo...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sentence: 2</td>\n      <td>Families of soldiers killed in the conflict jo...</td>\n      <td>[NNS, IN, NNS, VBN, IN, DT, NN, VBD, DT, NNS, ...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Sentence: 3</td>\n      <td>They marched from the Houses of Parliament to ...</td>\n      <td>[PRP, VBD, IN, DT, NNS, IN, NN, TO, DT, NN, IN...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, B-geo, I-geo...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Sentence: 4</td>\n      <td>Police put the number of marchers at 10,000 wh...</td>\n      <td>[NNS, VBD, DT, NN, IN, NNS, IN, CD, IN, NNS, V...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sentence: 5</td>\n      <td>The protest comes on the eve of the annual con...</td>\n      <td>[DT, NN, VBZ, IN, DT, NN, IN, DT, JJ, NN, IN, ...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, B-geo, O, O,...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X = data['Sentence'].values\ny_pos = data['POS'].values\ny_tag = data['Tag'].values","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:53:49.838818Z","iopub.execute_input":"2024-07-12T13:53:49.839120Z","iopub.status.idle":"2024-07-12T13:53:49.847264Z","shell.execute_reply.started":"2024-07-12T13:53:49.839094Z","shell.execute_reply":"2024-07-12T13:53:49.846473Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Распознование именнованных сущностей","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y_tag,test_size=0.2,random_state=42)\nprint(\"Train Data size:\", len(X_train))\nprint(\"Test Data size\", len(X_test))","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:53:49.848283Z","iopub.execute_input":"2024-07-12T13:53:49.848650Z","iopub.status.idle":"2024-07-12T13:53:49.871225Z","shell.execute_reply.started":"2024-07-12T13:53:49.848616Z","shell.execute_reply":"2024-07-12T13:53:49.870385Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Train Data size: 38367\nTest Data size 9592\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom collections import Counter","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:53:49.872243Z","iopub.execute_input":"2024-07-12T13:53:49.872516Z","iopub.status.idle":"2024-07-12T13:53:54.055885Z","shell.execute_reply.started":"2024-07-12T13:53:49.872493Z","shell.execute_reply":"2024-07-12T13:53:54.055018Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class MyTokenizer():\n    def __init__(self, max_words):\n        self.max_words = max_words\n    \n    def fit(self, texts):\n        words = Counter()\n        for text in texts:\n            for word in text.split():\n                words[word] += 1\n        top_words = sorted(words.items(), key=lambda item: item[1], reverse=True)[:self.max_words]\n        \n        self.vocab = {word[0]: i+1 for i, word in enumerate(top_words)}\n        self.vocab['<PAD>'] = 0\n        self.vocab['<UNK>'] = self.max_words+1\n        self.decode_vocab = {v: k for k, v in self.vocab.items()}\n\n    def token_to_id(self, token):\n        if token in self.vocab:\n            return self.vocab[token]\n        else:\n            return self.vocab['<UNK>']\n    \n    def encode(self, text):\n        arr = []\n        for word in text.split():\n            arr.append(self.token_to_id(word))\n        return arr\n    \n    def decode(self, sequence):\n        arr = []\n        for token in sequence:\n            if token in self.decode_vocab:\n                arr.append(self.decode_vocab[token])\n            else:\n                arr.append('<UNK>')\n        return ' '.join(arr)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:53:54.057055Z","iopub.execute_input":"2024-07-12T13:53:54.057501Z","iopub.status.idle":"2024-07-12T13:53:54.068820Z","shell.execute_reply.started":"2024-07-12T13:53:54.057474Z","shell.execute_reply":"2024-07-12T13:53:54.067845Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"tokenizer = MyTokenizer(25000)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:53:54.070476Z","iopub.execute_input":"2024-07-12T13:53:54.070868Z","iopub.status.idle":"2024-07-12T13:53:54.093946Z","shell.execute_reply.started":"2024-07-12T13:53:54.070834Z","shell.execute_reply":"2024-07-12T13:53:54.092986Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"tokenizer.fit(X_train)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:53:54.099383Z","iopub.execute_input":"2024-07-12T13:53:54.099716Z","iopub.status.idle":"2024-07-12T13:53:54.470413Z","shell.execute_reply.started":"2024-07-12T13:53:54.099677Z","shell.execute_reply":"2024-07-12T13:53:54.469623Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"class TextDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, tag2idx, max_len=100):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        \n        tags = set([val for sublist in self.labels for val in sublist])\n        self.tag2idx = tag2idx\n\n    def __len__(self):\n        return len(self.texts)\n    \n    def encode_labels(self, labels):\n        arr = []\n        for label in labels:\n            arr.append(self.tag2idx[label])\n        return arr\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = self.labels[idx]\n        encoded_text = self.tokenizer.encode(text)\n        encoded_label = self.encode_labels(label)\n        \n        if len(encoded_text) > self.max_len:\n            encoded_text = encoded_text[:self.max_len]\n            encoded_label = encoded_label[:self.max_len]\n        else: \n            encoded_text += [self.tokenizer.token_to_id(\"<PAD>\")] * (self.max_len - len(encoded_text))\n            encoded_label += [self.tag2idx['O']] * (self.max_len - len(encoded_label))\n        \n        return torch.tensor(encoded_text), torch.tensor(encoded_label)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:53:54.471691Z","iopub.execute_input":"2024-07-12T13:53:54.472180Z","iopub.status.idle":"2024-07-12T13:53:54.482204Z","shell.execute_reply.started":"2024-07-12T13:53:54.472146Z","shell.execute_reply":"2024-07-12T13:53:54.481286Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tags = set([val for sublist in y_train for val in sublist])\ntag2idx = {k: v for v,k in enumerate(tags)}\nidx2tag = {v: k for k, v in tag2idx.items()}\ntag2idx","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:53:54.483342Z","iopub.execute_input":"2024-07-12T13:53:54.483676Z","iopub.status.idle":"2024-07-12T13:53:54.568615Z","shell.execute_reply.started":"2024-07-12T13:53:54.483644Z","shell.execute_reply":"2024-07-12T13:53:54.567725Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"{'B-geo': 0,\n 'B-art': 1,\n 'B-eve': 2,\n 'I-art': 3,\n 'O': 4,\n 'I-geo': 5,\n 'I-org': 6,\n 'B-gpe': 7,\n 'B-tim': 8,\n 'B-per': 9,\n 'I-eve': 10,\n 'B-org': 11,\n 'I-tim': 12,\n 'B-nat': 13,\n 'I-nat': 14,\n 'I-gpe': 15,\n 'I-per': 16}"},"metadata":{}}]},{"cell_type":"code","source":"train_dataset = TextDataset(X_train, y_train, tokenizer, tag2idx)\ntrain_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, drop_last=True)\n\ntest_dataset = TextDataset(X_test, y_test, tokenizer, tag2idx)\ntest_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=True, drop_last=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:53:54.569856Z","iopub.execute_input":"2024-07-12T13:53:54.570237Z","iopub.status.idle":"2024-07-12T13:53:54.664383Z","shell.execute_reply.started":"2024-07-12T13:53:54.570208Z","shell.execute_reply":"2024-07-12T13:53:54.663301Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset[14931]","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:53:54.666035Z","iopub.execute_input":"2024-07-12T13:53:54.666346Z","iopub.status.idle":"2024-07-12T13:53:54.717273Z","shell.execute_reply.started":"2024-07-12T13:53:54.666318Z","shell.execute_reply":"2024-07-12T13:53:54.716314Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"(tensor([12600,    23,     1,    24,   977,   200,  2178,    10, 23702, 23703,\n          2590,    28,  7644,     1,  5968,     8,    25,    35,   336,  1987,\n           669, 16575,   436,     5,  3542,    22,   308,   429,     2,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n tensor([ 4,  4,  4,  0,  4,  4, 11,  4, 11,  6,  6,  4,  4,  4,  4,  4,  4,  4,\n          4,  4,  4,  4,  4,  4,  0,  4,  8, 12,  4,  4,  4,  4,  4,  4,  4,  4,\n          4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n          4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n          4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n          4,  4,  4,  4,  4,  4,  4,  4,  4,  4]))"},"metadata":{}}]},{"cell_type":"code","source":"class NER_LSTM(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, pad_idx):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size+1000, embedding_dim, padding_idx=pad_idx)\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, batch_first=True, bidirectional=True)\n        self.fc = nn.Linear(hidden_dim*2, output_dim)\n\n    def forward(self, text, text_lengths):\n        embedded = self.embedding(text)\n        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths, batch_first=True, enforce_sorted=False)\n        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n        output, _ = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n        return self.fc(output)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:53:54.718352Z","iopub.execute_input":"2024-07-12T13:53:54.718675Z","iopub.status.idle":"2024-07-12T13:53:54.727075Z","shell.execute_reply.started":"2024-07-12T13:53:54.718643Z","shell.execute_reply":"2024-07-12T13:53:54.726018Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"INPUT_DIM = len(tokenizer.vocab)+1\nEMBEDDING_DIM = 100\nHIDDEN_DIM = 256\nOUTPUT_DIM = len(train_dataset.tag2idx)\nN_LAYERS = 2\nPAD_IDX = tokenizer.token_to_id(\"<PAD>\")\nUNDEF_IDX = tag2idx['O']\n\nmodel_lstm = NER_LSTM(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, PAD_IDX)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:53:54.728356Z","iopub.execute_input":"2024-07-12T13:53:54.729846Z","iopub.status.idle":"2024-07-12T13:53:54.815077Z","shell.execute_reply.started":"2024-07-12T13:53:54.729816Z","shell.execute_reply":"2024-07-12T13:53:54.814007Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"model_lstm","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:53:54.816273Z","iopub.execute_input":"2024-07-12T13:53:54.816620Z","iopub.status.idle":"2024-07-12T13:53:54.822811Z","shell.execute_reply.started":"2024-07-12T13:53:54.816579Z","shell.execute_reply":"2024-07-12T13:53:54.821752Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"NER_LSTM(\n  (embedding): Embedding(26003, 100, padding_idx=0)\n  (lstm): LSTM(100, 256, num_layers=2, batch_first=True, bidirectional=True)\n  (fc): Linear(in_features=512, out_features=17, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"myit = iter(train_dataloader)\nt = next(myit)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:53:54.824042Z","iopub.execute_input":"2024-07-12T13:53:54.824330Z","iopub.status.idle":"2024-07-12T13:53:54.857194Z","shell.execute_reply.started":"2024-07-12T13:53:54.824305Z","shell.execute_reply":"2024-07-12T13:53:54.856365Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"lengths = torch.tensor([100 for _ in range(16)])\na, b = t\npredictions = model_lstm(a, lengths)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:53:54.858453Z","iopub.execute_input":"2024-07-12T13:53:54.858816Z","iopub.status.idle":"2024-07-12T13:53:55.253871Z","shell.execute_reply.started":"2024-07-12T13:53:54.858779Z","shell.execute_reply":"2024-07-12T13:53:55.252809Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"predictions.argmax(dim=-1)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:53:55.255129Z","iopub.execute_input":"2024-07-12T13:53:55.255889Z","iopub.status.idle":"2024-07-12T13:53:55.266917Z","shell.execute_reply.started":"2024-07-12T13:53:55.255852Z","shell.execute_reply":"2024-07-12T13:53:55.265883Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"tensor([[13, 13, 13,  ...,  2, 13, 13],\n        [ 2,  2,  2,  ...,  2, 13, 13],\n        [ 3,  3,  3,  ...,  2, 13, 13],\n        ...,\n        [13, 13, 13,  ...,  2, 13, 13],\n        [13, 13, 13,  ...,  2, 13, 13],\n        [ 2,  2,  2,  ...,  2, 13, 13]])"},"metadata":{}}]},{"cell_type":"code","source":"model_lstm","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:53:55.268295Z","iopub.execute_input":"2024-07-12T13:53:55.268707Z","iopub.status.idle":"2024-07-12T13:53:55.275621Z","shell.execute_reply.started":"2024-07-12T13:53:55.268671Z","shell.execute_reply":"2024-07-12T13:53:55.274636Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"NER_LSTM(\n  (embedding): Embedding(26003, 100, padding_idx=0)\n  (lstm): LSTM(100, 256, num_layers=2, batch_first=True, bidirectional=True)\n  (fc): Linear(in_features=512, out_features=17, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"def train_model(model, dataloader, optimizer, criterion, device):\n    model.train()\n    epoch_loss = 0\n    lengths = torch.tensor([100 for _ in range(16)])\n    for batch in tqdm(dataloader):\n        texts, labels = batch\n        texts, labels = texts.to(device), labels.to(device)\n        optimizer.zero_grad()\n        predictions = model(texts, lengths)\n        loss = criterion(predictions.transpose(-1, -2), labels)\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n    return epoch_loss / len(dataloader)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:53:55.276963Z","iopub.execute_input":"2024-07-12T13:53:55.277357Z","iopub.status.idle":"2024-07-12T13:53:55.286092Z","shell.execute_reply.started":"2024-07-12T13:53:55.277322Z","shell.execute_reply":"2024-07-12T13:53:55.285055Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"UNDEF_IDX","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:53:55.287516Z","iopub.execute_input":"2024-07-12T13:53:55.288032Z","iopub.status.idle":"2024-07-12T13:53:55.298633Z","shell.execute_reply.started":"2024-07-12T13:53:55.287995Z","shell.execute_reply":"2024-07-12T13:53:55.297585Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"4"},"metadata":{}}]},{"cell_type":"code","source":"idx2tag","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:53:55.300131Z","iopub.execute_input":"2024-07-12T13:53:55.300526Z","iopub.status.idle":"2024-07-12T13:53:55.309886Z","shell.execute_reply.started":"2024-07-12T13:53:55.300489Z","shell.execute_reply":"2024-07-12T13:53:55.309025Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"{0: 'B-geo',\n 1: 'B-art',\n 2: 'B-eve',\n 3: 'I-art',\n 4: 'O',\n 5: 'I-geo',\n 6: 'I-org',\n 7: 'B-gpe',\n 8: 'B-tim',\n 9: 'B-per',\n 10: 'I-eve',\n 11: 'B-org',\n 12: 'I-tim',\n 13: 'B-nat',\n 14: 'I-nat',\n 15: 'I-gpe',\n 16: 'I-per'}"},"metadata":{}}]},{"cell_type":"code","source":"def evaluate_model(model, dataloader, criterion, device):\n    model.eval()\n    epoch_loss = 0\n    all_preds = []\n    all_labels = []\n    lengths = torch.tensor([100 for _ in range(16)])\n    with torch.no_grad():\n        for batch in tqdm(dataloader):\n            texts, labels = batch\n            texts, labels = texts.to(device), labels.to(device)\n            predictions = model(texts, lengths)\n            \n            loss = criterion(predictions.transpose(-1, -2), labels)\n            epoch_loss += loss.item()\n            \n            predictions = predictions.argmax(dim=-1).cpu().numpy()\n            labels = labels.cpu().numpy()\n            for pred, label in zip(predictions, labels):\n                all_preds.append([idx2tag[p] for p in pred ])\n                all_labels.append([idx2tag[l] for l in label])\n    f1 = f1_score(all_labels, all_preds)\n    report = classification_report(all_labels, all_preds)\n    \n    return epoch_loss / len(dataloader), f1, report","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:53:55.311310Z","iopub.execute_input":"2024-07-12T13:53:55.311679Z","iopub.status.idle":"2024-07-12T13:53:55.321384Z","shell.execute_reply.started":"2024-07-12T13:53:55.311636Z","shell.execute_reply":"2024-07-12T13:53:55.320651Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:53:55.322526Z","iopub.execute_input":"2024-07-12T13:53:55.322815Z","iopub.status.idle":"2024-07-12T13:53:55.394534Z","shell.execute_reply.started":"2024-07-12T13:53:55.322774Z","shell.execute_reply":"2024-07-12T13:53:55.393464Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"optimizer = optim.Adam(model_lstm.parameters())\ncriterion = nn.CrossEntropyLoss()\nmodel_lstm = model_lstm.to(device)\ncriterion = criterion.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:53:55.396017Z","iopub.execute_input":"2024-07-12T13:53:55.397185Z","iopub.status.idle":"2024-07-12T13:53:57.295878Z","shell.execute_reply.started":"2024-07-12T13:53:55.397144Z","shell.execute_reply":"2024-07-12T13:53:57.294768Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"max(list(tokenizer.vocab.values()))","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:53:57.297182Z","iopub.execute_input":"2024-07-12T13:53:57.297730Z","iopub.status.idle":"2024-07-12T13:53:57.305811Z","shell.execute_reply.started":"2024-07-12T13:53:57.297697Z","shell.execute_reply":"2024-07-12T13:53:57.304619Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"25001"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loss, f1, report = evaluate_model(model_lstm, test_dataloader, criterion, device)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:53:57.307015Z","iopub.execute_input":"2024-07-12T13:53:57.307325Z","iopub.status.idle":"2024-07-12T13:54:27.007798Z","shell.execute_reply.started":"2024-07-12T13:53:57.307299Z","shell.execute_reply":"2024-07-12T13:54:27.006635Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"100%|██████████| 599/599 [00:05<00:00, 111.09it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(report)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:54:27.009455Z","iopub.execute_input":"2024-07-12T13:54:27.009769Z","iopub.status.idle":"2024-07-12T13:54:27.014621Z","shell.execute_reply.started":"2024-07-12T13:54:27.009742Z","shell.execute_reply":"2024-07-12T13:54:27.013622Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"           precision    recall  f1-score   support\n\n      geo       0.00      0.00      0.00      7658\n      tim       0.03      0.00      0.00      4044\n      org       0.00      0.00      0.00      3904\n      per       0.00      0.01      0.01      3386\n      gpe       0.01      0.03      0.01      3170\n      nat       0.00      0.22      0.00        50\n      eve       0.00      0.13      0.00        60\n      art       0.00      0.00      0.00        86\n\nmicro avg       0.00      0.01      0.00     22358\nmacro avg       0.01      0.01      0.00     22358\n\n","output_type":"stream"}]},{"cell_type":"code","source":"NUM_EPOCHS = 4\nfor epoch in range(NUM_EPOCHS):\n    train_loss = train_model(model_lstm, train_dataloader, optimizer, criterion, device)\n    print(f'Epoch {epoch+1}/{NUM_EPOCHS}, Training Loss: {train_loss:.4f}')\n\n    test_loss, f1, report = evaluate_model(model_lstm, test_dataloader, criterion, device)\n    print(f'Test Loss: {test_loss:.4f}, Test f1: {f1:.4f}')\n    print(report)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:54:27.015957Z","iopub.execute_input":"2024-07-12T13:54:27.016246Z","iopub.status.idle":"2024-07-12T13:58:44.378359Z","shell.execute_reply.started":"2024-07-12T13:54:27.016222Z","shell.execute_reply":"2024-07-12T13:58:44.377380Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"100%|██████████| 2397/2397 [00:42<00:00, 56.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/4, Training Loss: 0.0600\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 599/599 [00:04<00:00, 122.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss: 0.0298, Test f1: 0.7753\n           precision    recall  f1-score   support\n\n      geo       0.84      0.84      0.84      7658\n      tim       0.83      0.80      0.82      4046\n      per       0.64      0.67      0.66      3386\n      gpe       0.93      0.91      0.92      3172\n      art       0.00      0.00      0.00        86\n      org       0.67      0.55      0.60      3910\n      nat       0.00      0.00      0.00        50\n      eve       0.67      0.13      0.22        60\n\nmicro avg       0.79      0.76      0.78     22368\nmacro avg       0.79      0.76      0.77     22368\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2397/2397 [00:42<00:00, 56.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/4, Training Loss: 0.0231\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 599/599 [00:04<00:00, 121.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss: 0.0243, Test f1: 0.8037\n           precision    recall  f1-score   support\n\n      org       0.68      0.60      0.64      3910\n      geo       0.85      0.87      0.86      7660\n      gpe       0.95      0.93      0.94      3171\n      tim       0.85      0.85      0.85      4046\n      per       0.69      0.72      0.71      3383\n      eve       0.28      0.18      0.22        60\n      art       0.00      0.00      0.00        86\n      nat       0.26      0.12      0.16        50\n\nmicro avg       0.81      0.80      0.80     22366\nmacro avg       0.81      0.80      0.80     22366\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2397/2397 [00:43<00:00, 55.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/4, Training Loss: 0.0156\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 599/599 [00:04<00:00, 121.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss: 0.0247, Test f1: 0.8085\n           precision    recall  f1-score   support\n\n      geo       0.86      0.87      0.86      7659\n      gpe       0.95      0.93      0.94      3172\n      org       0.66      0.65      0.65      3913\n      tim       0.88      0.83      0.85      4043\n      per       0.73      0.70      0.71      3387\n      nat       0.50      0.24      0.32        50\n      eve       0.34      0.20      0.25        60\n      art       0.00      0.00      0.00        86\n\nmicro avg       0.82      0.80      0.81     22370\nmacro avg       0.81      0.80      0.81     22370\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2397/2397 [00:42<00:00, 55.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/4, Training Loss: 0.0105\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 599/599 [00:05<00:00, 119.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss: 0.0263, Test f1: 0.8058\n           precision    recall  f1-score   support\n\n      gpe       0.96      0.92      0.94      3173\n      geo       0.83      0.88      0.86      7662\n      tim       0.85      0.84      0.85      4047\n      org       0.67      0.63      0.65      3913\n      per       0.71      0.72      0.71      3386\n      nat       0.62      0.26      0.37        50\n      art       0.13      0.07      0.09        86\n      eve       0.31      0.20      0.24        60\n\nmicro avg       0.81      0.81      0.81     22377\nmacro avg       0.80      0.81      0.80     22377\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## ","metadata":{}},{"cell_type":"markdown","source":"#### BERT","metadata":{}},{"cell_type":"code","source":"from transformers import BertTokenizer, BertForTokenClassification","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:58:44.379681Z","iopub.execute_input":"2024-07-12T13:58:44.379964Z","iopub.status.idle":"2024-07-12T13:58:45.746928Z","shell.execute_reply.started":"2024-07-12T13:58:44.379939Z","shell.execute_reply":"2024-07-12T13:58:45.745825Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\nbert_model = BertForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=OUTPUT_DIM)  # Set NUM_LABELS according to your dataset\n","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:58:45.748073Z","iopub.execute_input":"2024-07-12T13:58:45.748520Z","iopub.status.idle":"2024-07-12T13:58:49.988254Z","shell.execute_reply.started":"2024-07-12T13:58:45.748493Z","shell.execute_reply":"2024-07-12T13:58:49.987461Z"},"trusted":true},"execution_count":37,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eac5543eb1014fdabae1a12b604d2feb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1628df140ae4c8bba1163dcf7f1b9a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c1835a55a1344768e2f223531dfff05"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a08702a88d4042c0950a7307b4412e32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5da9f2ba1f844c56932f83f50b48348d"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"class BERT_CLF(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super().__init__()\n        self.lin1 = nn.Linear(input_dim, input_dim)\n        self.lin2 = nn.Linear(input_dim, output_dim)\n        self.dropout = nn.Dropout(p=0.2)\n\n    def forward(self, seq):\n        output = self.lin2(self.dropout(self.lin1(seq)))\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:58:49.989407Z","iopub.execute_input":"2024-07-12T13:58:49.989683Z","iopub.status.idle":"2024-07-12T13:58:49.995536Z","shell.execute_reply.started":"2024-07-12T13:58:49.989659Z","shell.execute_reply":"2024-07-12T13:58:49.994619Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"bert_clf = BERT_CLF(768,17)\nbert_model.classifier=bert_clf","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:58:49.997303Z","iopub.execute_input":"2024-07-12T13:58:49.997725Z","iopub.status.idle":"2024-07-12T13:58:50.031927Z","shell.execute_reply.started":"2024-07-12T13:58:49.997687Z","shell.execute_reply":"2024-07-12T13:58:50.030975Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"bert_model","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:58:50.032995Z","iopub.execute_input":"2024-07-12T13:58:50.033248Z","iopub.status.idle":"2024-07-12T13:58:50.041534Z","shell.execute_reply.started":"2024-07-12T13:58:50.033226Z","shell.execute_reply":"2024-07-12T13:58:50.040618Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"BertForTokenClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): BERT_CLF(\n    (lin1): Linear(in_features=768, out_features=768, bias=True)\n    (lin2): Linear(in_features=768, out_features=17, bias=True)\n    (dropout): Dropout(p=0.2, inplace=False)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"def tokenize_and_preserve_labels(sentence, text_labels):\n    tokenized_sentence = []\n    labels = []\n\n    for word, label in zip(sentence.split(), text_labels):\n        tokenized_word = bert_tokenizer.tokenize(word)\n        n_subwords = len(tokenized_word)\n        tokenized_sentence.extend(tokenized_word)\n        labels.extend([label] * n_subwords)\n\n    return tokenized_sentence, labels","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:58:50.048992Z","iopub.execute_input":"2024-07-12T13:58:50.049319Z","iopub.status.idle":"2024-07-12T13:58:50.054775Z","shell.execute_reply.started":"2024-07-12T13:58:50.049296Z","shell.execute_reply":"2024-07-12T13:58:50.053810Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_texts_and_labels = [tokenize_and_preserve_labels(sent, labs) for sent, labs in zip(X, y_tag)]","metadata":{"execution":{"iopub.status.busy":"2024-07-12T13:58:50.055935Z","iopub.execute_input":"2024-07-12T13:58:50.056220Z","iopub.status.idle":"2024-07-12T14:00:14.960460Z","shell.execute_reply.started":"2024-07-12T13:58:50.056195Z","shell.execute_reply":"2024-07-12T14:00:14.959430Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"tokenized_texts = [token_label_pair[0] for token_label_pair in tokenized_texts_and_labels]\nlabels = [token_label_pair[1] for token_label_pair in tokenized_texts_and_labels]","metadata":{"execution":{"iopub.status.busy":"2024-07-12T14:00:14.961864Z","iopub.execute_input":"2024-07-12T14:00:14.962218Z","iopub.status.idle":"2024-07-12T14:00:14.985299Z","shell.execute_reply.started":"2024-07-12T14:00:14.962169Z","shell.execute_reply":"2024-07-12T14:00:14.984283Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2024-07-12T14:00:14.986486Z","iopub.execute_input":"2024-07-12T14:00:14.986824Z","iopub.status.idle":"2024-07-12T14:00:28.184314Z","shell.execute_reply.started":"2024-07-12T14:00:14.986797Z","shell.execute_reply":"2024-07-12T14:00:28.183447Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stderr","text":"2024-07-12 14:00:17.221128: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-12 14:00:17.221239: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-12 14:00:17.398506: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"MAX_LEN = 100","metadata":{"execution":{"iopub.status.busy":"2024-07-12T14:00:28.185633Z","iopub.execute_input":"2024-07-12T14:00:28.186426Z","iopub.status.idle":"2024-07-12T14:00:28.191340Z","shell.execute_reply.started":"2024-07-12T14:00:28.186385Z","shell.execute_reply":"2024-07-12T14:00:28.190374Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"input_ids = tf.keras.utils.pad_sequences([bert_tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts], maxlen=MAX_LEN, dtype=\"long\", value=0.0, truncating=\"post\", padding=\"post\")\ntags = tf.keras.utils.pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels], maxlen=MAX_LEN, value=tag2idx[\"O\"], padding=\"post\", dtype=\"long\", truncating=\"post\")","metadata":{"execution":{"iopub.status.busy":"2024-07-12T14:00:28.192649Z","iopub.execute_input":"2024-07-12T14:00:28.192996Z","iopub.status.idle":"2024-07-12T14:00:30.436991Z","shell.execute_reply.started":"2024-07-12T14:00:28.192968Z","shell.execute_reply":"2024-07-12T14:00:30.435491Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(input_ids, tags,test_size=0.2,random_state=42)\nprint(\"Train Data size:\", len(X_train))\nprint(\"Test Data size\", len(X_test))","metadata":{"execution":{"iopub.status.busy":"2024-07-12T14:00:30.438560Z","iopub.execute_input":"2024-07-12T14:00:30.439004Z","iopub.status.idle":"2024-07-12T14:00:30.487781Z","shell.execute_reply.started":"2024-07-12T14:00:30.438962Z","shell.execute_reply":"2024-07-12T14:00:30.486655Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"Train Data size: 38367\nTest Data size 9592\n","output_type":"stream"}]},{"cell_type":"code","source":"class BertDataset(Dataset):\n    def __init__(self, inputs_ids, labels):\n        super(BertDataset, self).__init__()\n        \n        self.texts = inputs_ids\n        self.target = labels\n        \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, index):\n        \n        inputs = self.texts[index]\n        \n        mask = [float(i != 0.0) for i in inputs]\n\n        return {\n            'ids': torch.tensor(inputs, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long),\n            'target': torch.tensor(self.target[index], dtype=torch.long)\n            }\n\n    \n\nbert_dataset_train = BertDataset(X_train, y_train)\nbert_dataset_test = BertDataset(X_test, y_test)\n\nbert_dataloader_train = DataLoader(dataset=bert_dataset_train,batch_size=16)\nbert_dataloader_test = DataLoader(dataset=bert_dataset_test,batch_size=16)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T14:00:30.489054Z","iopub.execute_input":"2024-07-12T14:00:30.489336Z","iopub.status.idle":"2024-07-12T14:00:30.515279Z","shell.execute_reply.started":"2024-07-12T14:00:30.489311Z","shell.execute_reply":"2024-07-12T14:00:30.514239Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"bert_dataset_train[0]","metadata":{"execution":{"iopub.status.busy":"2024-07-12T14:00:30.516402Z","iopub.execute_input":"2024-07-12T14:00:30.516721Z","iopub.status.idle":"2024-07-12T14:00:30.535420Z","shell.execute_reply.started":"2024-07-12T14:00:30.516696Z","shell.execute_reply":"2024-07-12T14:00:30.534533Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"{'ids': tensor([ 1996,  5388,  1011,  2095,  1011,  2214,  2280, 12941,  2758,  2002,\n          3024,  2592,  2000,  2019,  2880,  2012,  1996,  5611,  8408,  1998,\n          2000,  2048,  2372,  1997,  1037, 19670,  2177,  2170,  1996,  2137,\n          3956,  2270,  3821,  2837,  1012,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n 'mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]),\n 'target': tensor([ 4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  7,\n          4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  0, 11,  6,  6,  4,  4,\n          4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n          4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n          4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n          4,  4,  4,  4,  4,  4,  4,  4,  4,  4])}"},"metadata":{}}]},{"cell_type":"code","source":"bert_model = bert_model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T14:00:30.536555Z","iopub.execute_input":"2024-07-12T14:00:30.536865Z","iopub.status.idle":"2024-07-12T14:00:30.672471Z","shell.execute_reply.started":"2024-07-12T14:00:30.536840Z","shell.execute_reply":"2024-07-12T14:00:30.671698Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"for param in bert_model.bert.parameters():\n    param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2024-07-12T14:00:30.673422Z","iopub.execute_input":"2024-07-12T14:00:30.673725Z","iopub.status.idle":"2024-07-12T14:00:30.679185Z","shell.execute_reply.started":"2024-07-12T14:00:30.673698Z","shell.execute_reply":"2024-07-12T14:00:30.678081Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"from transformers import AdamW, get_linear_schedule_with_warmup","metadata":{"execution":{"iopub.status.busy":"2024-07-12T14:00:30.680455Z","iopub.execute_input":"2024-07-12T14:00:30.681077Z","iopub.status.idle":"2024-07-12T14:00:30.699639Z","shell.execute_reply.started":"2024-07-12T14:00:30.681042Z","shell.execute_reply":"2024-07-12T14:00:30.698742Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"NUM_EPOCHS = 10\noptimizer_bert = AdamW(bert_model.parameters(), lr=3e-5, eps=1e-8)\ntotal_steps = len(train_dataloader) * NUM_EPOCHS\nscheduler = get_linear_schedule_with_warmup(optimizer_bert, num_warmup_steps=0, num_training_steps=total_steps)\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-07-12T14:00:30.700812Z","iopub.execute_input":"2024-07-12T14:00:30.701094Z","iopub.status.idle":"2024-07-12T14:00:30.712343Z","shell.execute_reply.started":"2024-07-12T14:00:30.701069Z","shell.execute_reply":"2024-07-12T14:00:30.711432Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_model_bert(model, dataloader, optimizer, device):\n    model.train()\n    epoch_loss = 0\n    for batch in tqdm(dataloader):\n        b_input_ids = batch['ids']\n        b_masks = batch['mask']\n        b_labels = batch['target']\n        \n        outputs = model(b_input_ids.to(device), token_type_ids=None, attention_mask=b_masks.to(device), labels=b_labels.to(device))\n        loss = criterion(outputs[1].transpose(-1, -2), b_labels.to(device))\n        loss.backward()\n        \n        optimizer.step()\n        scheduler.step()\n        model.zero_grad()\n        \n        epoch_loss += loss.item()\n        \n    return epoch_loss / len(dataloader)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T14:00:30.713722Z","iopub.execute_input":"2024-07-12T14:00:30.714433Z","iopub.status.idle":"2024-07-12T14:00:30.721861Z","shell.execute_reply.started":"2024-07-12T14:00:30.714401Z","shell.execute_reply":"2024-07-12T14:00:30.720759Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(logits_and_labels):\n    logits, labels = logits_and_labels \n      \n    # Get predictions from the logits\n    predictions = np.argmax(logits, axis=-1)\n\n    # Remove ignored index (special tokens)\n    str_labels = [\n        [label_names[t] for t in label if t!=-100] for label in labels\n    ]\n\n    str_preds = [\n        [label_names[p] for (p, t) in zip(prediction, label) if t != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n\n    # Compute metrics\n    results = metric.compute(predictions=str_preds, references=str_labels)\n\n    return {\n        \"precision\": results[\"overall_precision\"],\n        \"recall\": results[\"overall_recall\"], \n        \"f1\": results[\"overall_f1\"],\n        \"accuracy\": results[\"overall_accuracy\"]  \n    }","metadata":{"execution":{"iopub.status.busy":"2024-07-12T14:00:30.723044Z","iopub.execute_input":"2024-07-12T14:00:30.723361Z","iopub.status.idle":"2024-07-12T14:00:30.733425Z","shell.execute_reply.started":"2024-07-12T14:00:30.723328Z","shell.execute_reply":"2024-07-12T14:00:30.732470Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"def evaluate_model_bert(model, dataloader, device):\n    model.eval()\n    epoch_loss = 0\n    all_preds = []\n    all_labels = []\n    lengths = torch.tensor([100 for _ in range(16)])\n    with torch.no_grad():\n        for batch in tqdm(dataloader):\n            b_input_ids = batch['ids']\n            b_masks = batch['mask']\n            b_labels = batch['target']\n\n            outputs = model(b_input_ids.to(device), token_type_ids=None, attention_mask=b_masks.to(device), labels=b_labels.to(device))\n            \n            loss = criterion(outputs[1].transpose(-1, -2), b_labels.to(device))\n            epoch_loss += loss.item()\n            \n            predictions = outputs[1].argmax(dim=-1).cpu().numpy()\n            labels = b_labels.cpu().numpy()\n            \n            for pred, label in zip(predictions, labels):\n                all_preds.append([idx2tag[p] for p in pred ])\n                all_labels.append([idx2tag[l] for l in label])\n    \n    f1 = f1_score(all_labels, all_preds)\n    report = classification_report(all_labels, all_preds)\n    \n    return epoch_loss / len(dataloader), f1, report","metadata":{"execution":{"iopub.status.busy":"2024-07-12T14:00:30.734681Z","iopub.execute_input":"2024-07-12T14:00:30.734998Z","iopub.status.idle":"2024-07-12T14:00:30.748306Z","shell.execute_reply.started":"2024-07-12T14:00:30.734974Z","shell.execute_reply":"2024-07-12T14:00:30.747400Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"myit = iter(bert_dataloader_train)\nbatch = next(myit)\nb_input_ids = batch['ids']\nb_masks = batch['mask']\nb_labels = batch['target']","metadata":{"execution":{"iopub.status.busy":"2024-07-12T14:00:30.749709Z","iopub.execute_input":"2024-07-12T14:00:30.750000Z","iopub.status.idle":"2024-07-12T14:00:30.766989Z","shell.execute_reply.started":"2024-07-12T14:00:30.749973Z","shell.execute_reply":"2024-07-12T14:00:30.766129Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"outputs = bert_model(b_input_ids.to(device), token_type_ids=None, attention_mask=b_masks.to(device), labels=b_labels.to(device))","metadata":{"execution":{"iopub.status.busy":"2024-07-12T14:00:30.768060Z","iopub.execute_input":"2024-07-12T14:00:30.768397Z","iopub.status.idle":"2024-07-12T14:00:31.016338Z","shell.execute_reply.started":"2024-07-12T14:00:30.768368Z","shell.execute_reply":"2024-07-12T14:00:31.015539Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"outputs[1].argmax(dim=-1)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T14:00:31.017363Z","iopub.execute_input":"2024-07-12T14:00:31.017717Z","iopub.status.idle":"2024-07-12T14:00:31.036311Z","shell.execute_reply.started":"2024-07-12T14:00:31.017690Z","shell.execute_reply":"2024-07-12T14:00:31.035488Z"},"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"tensor([[ 3,  9,  9,  ...,  8,  8,  8],\n        [ 6,  1,  8,  ...,  9,  9, 11],\n        [ 4,  9,  4,  ...,  4,  4,  4],\n        ...,\n        [ 8,  8,  9,  ...,  8,  3,  9],\n        [ 4,  3,  9,  ...,  9,  9,  8],\n        [ 0,  4,  4,  ...,  4,  4,  2]], device='cuda:0')"},"metadata":{}}]},{"cell_type":"code","source":"for epoch in range(NUM_EPOCHS):\n    train_loss = train_model_bert(bert_model, bert_dataloader_train, optimizer_bert, device)\n    print(f'Epoch {epoch+1}/{NUM_EPOCHS}, Training Loss: {train_loss:.4f}')\n\n    test_loss, f1, report = evaluate_model_bert(bert_model, bert_dataloader_test, device)\n    print(f'Test Loss: {test_loss:.4f}, Test f1: {f1:.4f}')\n    print(report)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T14:00:31.037225Z","iopub.execute_input":"2024-07-12T14:00:31.037507Z","iopub.status.idle":"2024-07-12T14:50:43.304094Z","shell.execute_reply.started":"2024-07-12T14:00:31.037482Z","shell.execute_reply":"2024-07-12T14:50:43.303152Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stderr","text":"100%|██████████| 2398/2398 [03:48<00:00, 10.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10, Training Loss: 0.2385\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 600/600 [00:55<00:00, 10.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss: 0.1087, Test f1: 0.4285\n           precision    recall  f1-score   support\n\n      per       0.33      0.27      0.30      5186\n      art       0.00      0.00      0.00       146\n      geo       0.51      0.68      0.58     11526\n      org       0.31      0.14      0.19      6390\n      tim       0.53      0.31      0.39      4380\n      gpe       0.75      0.23      0.35      3453\n      nat       0.00      0.00      0.00        98\n      eve       0.00      0.00      0.00        68\n\nmicro avg       0.47      0.39      0.43     31247\nmacro avg       0.46      0.39      0.40     31247\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2398/2398 [03:48<00:00, 10.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/10, Training Loss: 0.1170\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 600/600 [00:55<00:00, 10.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss: 0.0883, Test f1: 0.5387\n           precision    recall  f1-score   support\n\n      per       0.44      0.43      0.44      5186\n      art       0.00      0.00      0.00       146\n      geo       0.59      0.73      0.65     11526\n      org       0.37      0.24      0.29      6390\n      tim       0.63      0.55      0.59      4380\n      gpe       0.71      0.57      0.63      3453\n      nat       0.00      0.00      0.00        98\n      eve       0.00      0.00      0.00        68\n\nmicro avg       0.55      0.53      0.54     31247\nmacro avg       0.53      0.53      0.52     31247\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2398/2398 [03:48<00:00, 10.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/10, Training Loss: 0.1057\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 600/600 [00:55<00:00, 10.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss: 0.0823, Test f1: 0.5691\n           precision    recall  f1-score   support\n\n      per       0.49      0.48      0.48      5186\n      art       0.00      0.00      0.00       146\n      geo       0.62      0.74      0.67     11526\n      org       0.40      0.27      0.32      6390\n      tim       0.66      0.59      0.63      4380\n      gpe       0.73      0.61      0.67      3453\n      nat       0.00      0.00      0.00        98\n      eve       0.00      0.00      0.00        68\n\nmicro avg       0.58      0.56      0.57     31247\nmacro avg       0.57      0.56      0.56     31247\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2398/2398 [03:49<00:00, 10.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/10, Training Loss: 0.1017\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 600/600 [00:55<00:00, 10.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss: 0.0798, Test f1: 0.5805\n           precision    recall  f1-score   support\n\n      per       0.50      0.49      0.49      5186\n      art       0.00      0.00      0.00       146\n      geo       0.63      0.74      0.68     11526\n      org       0.41      0.28      0.33      6390\n      tim       0.68      0.61      0.64      4380\n      gpe       0.74      0.64      0.68      3453\n      nat       0.00      0.00      0.00        98\n      eve       0.00      0.00      0.00        68\n\nmicro avg       0.59      0.57      0.58     31247\nmacro avg       0.58      0.57      0.57     31247\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2398/2398 [03:48<00:00, 10.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/10, Training Loss: 0.0999\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 600/600 [00:55<00:00, 10.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss: 0.0783, Test f1: 0.5878\n           precision    recall  f1-score   support\n\n      per       0.50      0.50      0.50      5186\n      art       0.00      0.00      0.00       146\n      geo       0.64      0.75      0.69     11526\n      org       0.42      0.30      0.35      6390\n      tim       0.69      0.62      0.65      4380\n      gpe       0.74      0.65      0.69      3453\n      nat       0.00      0.00      0.00        98\n      eve       0.00      0.00      0.00        68\n\nmicro avg       0.60      0.58      0.59     31247\nmacro avg       0.58      0.58      0.58     31247\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2398/2398 [03:48<00:00, 10.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/10, Training Loss: 0.0987\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 600/600 [00:55<00:00, 10.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss: 0.0774, Test f1: 0.5945\n           precision    recall  f1-score   support\n\n      per       0.50      0.52      0.51      5186\n      art       0.00      0.00      0.00       146\n      geo       0.65      0.75      0.69     11526\n      org       0.42      0.30      0.35      6390\n      tim       0.70      0.62      0.66      4380\n      gpe       0.74      0.66      0.70      3453\n      nat       0.00      0.00      0.00        98\n      eve       0.00      0.00      0.00        68\n\nmicro avg       0.60      0.59      0.59     31247\nmacro avg       0.59      0.59      0.58     31247\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2398/2398 [03:49<00:00, 10.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7/10, Training Loss: 0.0978\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 600/600 [00:55<00:00, 10.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss: 0.0770, Test f1: 0.5968\n           precision    recall  f1-score   support\n\n      per       0.51      0.53      0.52      5186\n      art       0.00      0.00      0.00       146\n      geo       0.65      0.75      0.69     11526\n      org       0.42      0.31      0.36      6390\n      tim       0.70      0.63      0.66      4380\n      gpe       0.74      0.66      0.70      3453\n      nat       0.00      0.00      0.00        98\n      eve       0.00      0.00      0.00        68\n\nmicro avg       0.60      0.59      0.60     31247\nmacro avg       0.59      0.59      0.59     31247\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2398/2398 [03:48<00:00, 10.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8/10, Training Loss: 0.0974\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 600/600 [00:55<00:00, 10.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss: 0.0766, Test f1: 0.5993\n           precision    recall  f1-score   support\n\n      per       0.51      0.53      0.52      5186\n      art       0.00      0.00      0.00       146\n      geo       0.65      0.75      0.70     11526\n      org       0.42      0.32      0.37      6390\n      tim       0.70      0.63      0.66      4380\n      gpe       0.74      0.66      0.70      3453\n      nat       0.00      0.00      0.00        98\n      eve       0.33      0.01      0.03        68\n\nmicro avg       0.61      0.59      0.60     31247\nmacro avg       0.59      0.59      0.59     31247\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2398/2398 [03:48<00:00, 10.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9/10, Training Loss: 0.0967\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 600/600 [00:55<00:00, 10.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss: 0.0762, Test f1: 0.5996\n           precision    recall  f1-score   support\n\n      per       0.51      0.53      0.52      5186\n      art       0.00      0.00      0.00       146\n      geo       0.66      0.75      0.70     11526\n      org       0.42      0.33      0.37      6390\n      tim       0.71      0.63      0.67      4380\n      gpe       0.74      0.67      0.70      3453\n      nat       0.00      0.00      0.00        98\n      eve       0.33      0.01      0.03        68\n\nmicro avg       0.61      0.59      0.60     31247\nmacro avg       0.60      0.59      0.59     31247\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2398/2398 [03:48<00:00, 10.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10/10, Training Loss: 0.0967\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 600/600 [00:55<00:00, 10.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss: 0.0761, Test f1: 0.6001\n           precision    recall  f1-score   support\n\n      per       0.52      0.53      0.52      5186\n      art       0.00      0.00      0.00       146\n      geo       0.66      0.74      0.70     11526\n      org       0.42      0.33      0.37      6390\n      tim       0.71      0.63      0.67      4380\n      gpe       0.74      0.67      0.70      3453\n      nat       0.00      0.00      0.00        98\n      eve       0.33      0.01      0.03        68\n\nmicro avg       0.61      0.59      0.60     31247\nmacro avg       0.60      0.59      0.59     31247\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}