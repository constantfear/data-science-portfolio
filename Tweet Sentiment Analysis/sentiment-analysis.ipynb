{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4140,"sourceType":"datasetVersion","datasetId":2477}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\n\nimport nltk \nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom tqdm import tqdm\n\nimport re","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-07T10:18:10.679250Z","iopub.execute_input":"2024-07-07T10:18:10.679973Z","iopub.status.idle":"2024-07-07T10:18:13.390733Z","shell.execute_reply.started":"2024-07-07T10:18:10.679940Z","shell.execute_reply":"2024-07-07T10:18:13.389822Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Read Data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/sentiment140/training.1600000.processed.noemoticon.csv',\n                 encoding = 'latin',header=None)\ndf.columns = ['sentiment', 'id', 'date', 'query', 'user_id', 'text']\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-07T10:18:13.392682Z","iopub.execute_input":"2024-07-07T10:18:13.393271Z","iopub.status.idle":"2024-07-07T10:18:19.488788Z","shell.execute_reply.started":"2024-07-07T10:18:13.393237Z","shell.execute_reply":"2024-07-07T10:18:19.487810Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   sentiment          id                          date     query  \\\n0          0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n1          0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n2          0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n3          0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n4          0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n\n           user_id                                               text  \n0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n1    scotthamilton  is upset that he can't update his Facebook by ...  \n2         mattycus  @Kenichan I dived many times for the ball. Man...  \n3          ElleCTF    my whole body feels itchy and like its on fire   \n4           Karoli  @nationwideclass no, it's not behaving at all....  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>id</th>\n      <th>date</th>\n      <th>query</th>\n      <th>user_id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1467810369</td>\n      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>_TheSpecialOne_</td>\n      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1467810672</td>\n      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>scotthamilton</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1467810917</td>\n      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>mattycus</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1467811184</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>ElleCTF</td>\n      <td>my whole body feels itchy and like its on fire</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1467811193</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>Karoli</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df = df.drop(['id', 'date', 'query', 'user_id'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T10:18:19.490100Z","iopub.execute_input":"2024-07-07T10:18:19.490481Z","iopub.status.idle":"2024-07-07T10:18:19.533106Z","shell.execute_reply.started":"2024-07-07T10:18:19.490444Z","shell.execute_reply":"2024-07-07T10:18:19.532396Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df.sentiment = df.sentiment.apply(lambda x: 0 if x == 0 else 1)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-07T10:18:19.535334Z","iopub.execute_input":"2024-07-07T10:18:19.535979Z","iopub.status.idle":"2024-07-07T10:18:20.614384Z","shell.execute_reply.started":"2024-07-07T10:18:19.535945Z","shell.execute_reply":"2024-07-07T10:18:20.613467Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   sentiment                                               text\n0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n1          0  is upset that he can't update his Facebook by ...\n2          0  @Kenichan I dived many times for the ball. Man...\n3          0    my whole body feels itchy and like its on fire \n4          0  @nationwideclass no, it's not behaving at all....","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>my whole body feels itchy and like its on fire</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Text preprocessing","metadata":{}},{"cell_type":"markdown","source":"Создадим словарь сокращений разговорной речи","metadata":{}},{"cell_type":"code","source":"abbreviation_dict = {\n    'lol': 'laugh out loud',\n    'brb': 'be right back',\n    'omg': 'oh my god',\n    'thx': 'thanks',\n    'hbd': 'happy birthday',\n    'ily': 'i love you',\n    'pls': 'please',\n    'ppl': 'people',\n    'asap': 'as soon as possible',\n    'otw': 'om the way',\n    'icymi': 'in case you missed it',\n    'tmi': 'too much information',\n    'idk': \"i don't know\",\n    'imo': 'in my opinion',\n    'imho': 'in my humble opinion',\n}","metadata":{"execution":{"iopub.status.busy":"2024-07-07T10:18:20.615658Z","iopub.execute_input":"2024-07-07T10:18:20.615966Z","iopub.status.idle":"2024-07-07T10:18:20.621403Z","shell.execute_reply.started":"2024-07-07T10:18:20.615941Z","shell.execute_reply":"2024-07-07T10:18:20.620266Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def expand_abbreviations(text):\n    pattern = re.compile(r'\\b(' + '|'.join(re.escape(key) for key in abbreviation_dict.keys()) + r')\\b')\n    expanded_text = pattern.sub(lambda x: abbreviation_dict[x.group()], text)\n    return expanded_text","metadata":{"execution":{"iopub.status.busy":"2024-07-07T10:18:20.622577Z","iopub.execute_input":"2024-07-07T10:18:20.622848Z","iopub.status.idle":"2024-07-07T10:18:20.632691Z","shell.execute_reply.started":"2024-07-07T10:18:20.622824Z","shell.execute_reply":"2024-07-07T10:18:20.631893Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"Напишем функцию полной предобработки текста","metadata":{}},{"cell_type":"code","source":"from nltk.stem.porter import PorterStemmer","metadata":{"execution":{"iopub.status.busy":"2024-07-07T10:18:20.634523Z","iopub.execute_input":"2024-07-07T10:18:20.634818Z","iopub.status.idle":"2024-07-07T10:18:20.643060Z","shell.execute_reply.started":"2024-07-07T10:18:20.634787Z","shell.execute_reply":"2024-07-07T10:18:20.642077Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"stop_words = set(stopwords.words('english'))\ntext_cleaning_re = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\nstemmer = PorterStemmer()","metadata":{"execution":{"iopub.status.busy":"2024-07-07T10:18:20.917605Z","iopub.execute_input":"2024-07-07T10:18:20.917909Z","iopub.status.idle":"2024-07-07T10:18:20.924309Z","shell.execute_reply.started":"2024-07-07T10:18:20.917884Z","shell.execute_reply":"2024-07-07T10:18:20.923481Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def preprocess_text(text):\n    text = text.lower()\n    text = re.sub(text_cleaning_re, ' ', text).strip()\n    text = expand_abbreviations(text)\n    text = \" \".join([stemmer.stem(word) for word in text.split() if word not in stop_words])\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-07-06T07:44:53.329389Z","iopub.execute_input":"2024-07-06T07:44:53.329862Z","iopub.status.idle":"2024-07-06T07:44:53.335554Z","shell.execute_reply.started":"2024-07-06T07:44:53.329831Z","shell.execute_reply":"2024-07-06T07:44:53.334602Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df['text_prepared'] = df.text.apply(lambda x: preprocess_text(x))","metadata":{"execution":{"iopub.status.busy":"2024-07-06T07:44:54.866611Z","iopub.execute_input":"2024-07-06T07:44:54.866962Z","iopub.status.idle":"2024-07-06T07:51:52.033391Z","shell.execute_reply.started":"2024-07-06T07:44:54.866935Z","shell.execute_reply":"2024-07-06T07:51:52.032386Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df.text_prepared[19]","metadata":{"execution":{"iopub.status.busy":"2024-07-06T07:51:52.035194Z","iopub.execute_input":"2024-07-06T07:51:52.035487Z","iopub.status.idle":"2024-07-06T07:51:52.041796Z","shell.execute_reply.started":"2024-07-06T07:51:52.035462Z","shell.execute_reply":"2024-07-06T07:51:52.040892Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'oh dear drink forgotten tabl drink'"},"metadata":{}}]},{"cell_type":"code","source":"X = np.array(df['text_prepared'])\ny = np.array(df['sentiment'])","metadata":{"execution":{"iopub.status.busy":"2024-07-06T07:51:52.042857Z","iopub.execute_input":"2024-07-06T07:51:52.043150Z","iopub.status.idle":"2024-07-06T07:51:52.076888Z","shell.execute_reply.started":"2024-07-06T07:51:52.043126Z","shell.execute_reply":"2024-07-06T07:51:52.076121Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Modeling","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                    stratify=y, \n                                                    test_size=0.2)\nprint(\"Train Data size:\", len(X_train))\nprint(\"Test Data size\", len(X_test))","metadata":{"execution":{"iopub.status.busy":"2024-07-06T07:51:52.079033Z","iopub.execute_input":"2024-07-06T07:51:52.079301Z","iopub.status.idle":"2024-07-06T07:51:52.741208Z","shell.execute_reply.started":"2024-07-06T07:51:52.079278Z","shell.execute_reply":"2024-07-06T07:51:52.740373Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Train Data size: 1280000\nTest Data size 320000\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### LogReg","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression","metadata":{"execution":{"iopub.status.busy":"2024-07-05T11:18:39.401944Z","iopub.execute_input":"2024-07-05T11:18:39.402369Z","iopub.status.idle":"2024-07-05T11:18:39.407877Z","shell.execute_reply.started":"2024-07-05T11:18:39.402335Z","shell.execute_reply":"2024-07-05T11:18:39.406440Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"vectorizer = CountVectorizer()\nX_train_vec = vectorizer.fit_transform(X_train)\nX_text_vec = vectorizer.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-07-05T11:28:48.297315Z","iopub.execute_input":"2024-07-05T11:28:48.297763Z","iopub.status.idle":"2024-07-05T11:29:11.915654Z","shell.execute_reply.started":"2024-07-05T11:28:48.297728Z","shell.execute_reply":"2024-07-05T11:29:11.914594Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"model_logreg = LogisticRegression(solver='lbfgs', max_iter=1000)\nmodel_logreg.fit(X_train_vec, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-07-05T11:29:11.917504Z","iopub.execute_input":"2024-07-05T11:29:11.918206Z","iopub.status.idle":"2024-07-05T11:33:27.740795Z","shell.execute_reply.started":"2024-07-05T11:29:11.918173Z","shell.execute_reply":"2024-07-05T11:33:27.739269Z"},"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"LogisticRegression(max_iter=1000)","text/html":"<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2024-07-05T11:33:56.703071Z","iopub.execute_input":"2024-07-05T11:33:56.703447Z","iopub.status.idle":"2024-07-05T11:33:56.709075Z","shell.execute_reply.started":"2024-07-05T11:33:56.703417Z","shell.execute_reply":"2024-07-05T11:33:56.707696Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_text_vec)\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-07-05T12:03:14.730240Z","iopub.execute_input":"2024-07-05T12:03:14.730782Z","iopub.status.idle":"2024-07-05T12:03:14.860732Z","shell.execute_reply.started":"2024-07-05T12:03:14.730742Z","shell.execute_reply":"2024-07-05T12:03:14.859380Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"Accuracy: 0.77300625\nConfusion Matrix:\n [[119832  40168]\n [ 32470 127530]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### LogReg with TF-IDF","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer","metadata":{"execution":{"iopub.status.busy":"2024-07-05T12:13:52.990990Z","iopub.execute_input":"2024-07-05T12:13:52.991425Z","iopub.status.idle":"2024-07-05T12:13:52.997598Z","shell.execute_reply.started":"2024-07-05T12:13:52.991390Z","shell.execute_reply":"2024-07-05T12:13:52.996041Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"vectorizer_tfidf = TfidfVectorizer()\nX_train_tfidf = vectorizer_tfidf.fit_transform(X_train)\nX_text_tfidf = vectorizer_tfidf.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-07-05T12:31:49.691293Z","iopub.execute_input":"2024-07-05T12:31:49.692285Z","iopub.status.idle":"2024-07-05T12:32:14.029061Z","shell.execute_reply.started":"2024-07-05T12:31:49.692244Z","shell.execute_reply":"2024-07-05T12:32:14.027728Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"model_tfidf = LogisticRegression(solver='lbfgs', max_iter=1000)\nmodel_tfidf.fit(X_train_tfidf, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-07-05T12:32:14.031409Z","iopub.execute_input":"2024-07-05T12:32:14.031812Z","iopub.status.idle":"2024-07-05T12:34:09.836196Z","shell.execute_reply.started":"2024-07-05T12:32:14.031780Z","shell.execute_reply":"2024-07-05T12:34:09.834693Z"},"trusted":true},"execution_count":70,"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"LogisticRegression(max_iter=1000)","text/html":"<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"y_pred = model_tfidf.predict(X_text_tfidf)\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-07-05T12:34:09.838241Z","iopub.execute_input":"2024-07-05T12:34:09.839095Z","iopub.status.idle":"2024-07-05T12:34:09.994349Z","shell.execute_reply.started":"2024-07-05T12:34:09.839042Z","shell.execute_reply":"2024-07-05T12:34:09.993097Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"Accuracy: 0.774915625\nConfusion Matrix:\n [[120882  39118]\n [ 32909 127091]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### LSTM","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom collections import Counter","metadata":{"execution":{"iopub.status.busy":"2024-07-07T10:18:50.215863Z","iopub.execute_input":"2024-07-07T10:18:50.216469Z","iopub.status.idle":"2024-07-07T10:18:53.925560Z","shell.execute_reply.started":"2024-07-07T10:18:50.216437Z","shell.execute_reply":"2024-07-07T10:18:53.924797Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class MyTokenizer():\n    def __init__(self, max_words):\n        self.max_words = max_words\n    \n    def fit(self, texts):\n        words = Counter()\n        for text in texts:\n            for word in text.split():\n                words[word] += 1\n        top_words = sorted(words.items(), key=lambda item: item[1], reverse=True)[:self.max_words]\n        \n        self.vocab = {word[0]: i+1 for i, word in enumerate(top_words)}\n        self.vocab['<PAD>'] = 0\n        self.vocab['<UNK>'] = self.max_words+1\n        self.decode_vocab = {v: k for k, v in self.vocab.items()}\n\n    def token_to_id(self, token):\n        if token in self.vocab:\n            return self.vocab[token]\n        else:\n            return self.vocab['<UNK>']\n    \n    def encode(self, text):\n        arr = []\n        for word in text.split():\n            if word in self.vocab:\n                arr.append(self.vocab[word])\n            else:\n                arr.append(self.vocab['<UNK>'])\n        return arr\n    \n    def decode(self, sequence):\n        arr = []\n        for token in sequence:\n            if token in self.decode_vocab:\n                arr.append(self.decode_vocab[token])\n            else:\n                arr.append('<UNK>')\n        return ' '.join(arr)\n        ","metadata":{"execution":{"iopub.status.busy":"2024-07-07T10:18:59.831148Z","iopub.execute_input":"2024-07-07T10:18:59.831657Z","iopub.status.idle":"2024-07-07T10:18:59.842761Z","shell.execute_reply.started":"2024-07-07T10:18:59.831625Z","shell.execute_reply":"2024-07-07T10:18:59.841836Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"tokenizer = MyTokenizer(10000)","metadata":{"execution":{"iopub.status.busy":"2024-07-06T07:51:56.882038Z","iopub.execute_input":"2024-07-06T07:51:56.882267Z","iopub.status.idle":"2024-07-06T07:51:56.891424Z","shell.execute_reply.started":"2024-07-06T07:51:56.882247Z","shell.execute_reply":"2024-07-06T07:51:56.890688Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"tokenizer.fit(X_train)","metadata":{"execution":{"iopub.status.busy":"2024-07-06T07:51:56.892541Z","iopub.execute_input":"2024-07-06T07:51:56.892809Z","iopub.status.idle":"2024-07-06T07:52:01.054665Z","shell.execute_reply.started":"2024-07-06T07:51:56.892787Z","shell.execute_reply":"2024-07-06T07:52:01.053681Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"tokenizer.decode(tokenizer.encode('oh dear drink forgotten tabl drink'))","metadata":{"execution":{"iopub.status.busy":"2024-07-06T07:52:01.055932Z","iopub.execute_input":"2024-07-06T07:52:01.056238Z","iopub.status.idle":"2024-07-06T07:52:01.062301Z","shell.execute_reply.started":"2024-07-06T07:52:01.056212Z","shell.execute_reply":"2024-07-06T07:52:01.061444Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"'oh dear drink forgotten tabl drink'"},"metadata":{}}]},{"cell_type":"code","source":"class TextDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len=25):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = self.labels[idx]\n        encoded_text = self.tokenizer.encode(text)\n        if len(encoded_text) > self.max_len:\n            encoded_text = encoded_text[:self.max_len]\n        else:\n            encoded_text += [self.tokenizer.token_to_id(\"<PAD>\")] * (self.max_len - len(encoded_text))\n        return torch.tensor(encoded_text), torch.tensor(label)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T07:02:50.158227Z","iopub.execute_input":"2024-07-07T07:02:50.159149Z","iopub.status.idle":"2024-07-07T07:02:50.166510Z","shell.execute_reply.started":"2024-07-07T07:02:50.159105Z","shell.execute_reply":"2024-07-07T07:02:50.165745Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train_dataset = TextDataset(X_train, y_train, tokenizer)\ntrain_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n\ntest_dataset = TextDataset(X_test, y_test, tokenizer)\ntest_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-06T07:52:01.074882Z","iopub.execute_input":"2024-07-06T07:52:01.075170Z","iopub.status.idle":"2024-07-06T07:52:01.088899Z","shell.execute_reply.started":"2024-07-06T07:52:01.075148Z","shell.execute_reply":"2024-07-06T07:52:01.088090Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"class TextLSTM(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, pad_idx):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, text, text_lengths):\n        embedded = self.embedding(text)\n        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths, batch_first=True, enforce_sorted=False)\n        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n        hidden = hidden[-1,:,:]\n        return self.fc(hidden)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T07:02:52.483842Z","iopub.execute_input":"2024-07-07T07:02:52.484727Z","iopub.status.idle":"2024-07-07T07:02:52.491969Z","shell.execute_reply.started":"2024-07-07T07:02:52.484672Z","shell.execute_reply":"2024-07-07T07:02:52.491046Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"INPUT_DIM = len(tokenizer.vocab)\nEMBEDDING_DIM = 100\nHIDDEN_DIM = 256\nOUTPUT_DIM = 1\nN_LAYERS = 2\nPAD_IDX = tokenizer.token_to_id(\"<pad>\")\n\nmodel_lstm = TextLSTM(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, PAD_IDX)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T07:03:45.458460Z","iopub.execute_input":"2024-07-07T07:03:45.459427Z","iopub.status.idle":"2024-07-07T07:03:45.599358Z","shell.execute_reply.started":"2024-07-07T07:03:45.459383Z","shell.execute_reply":"2024-07-07T07:03:45.598437Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def train_model(model, dataloader, optimizer, criterion, device):\n    model.train()\n    epoch_loss = 0\n    for batch in tqdm(dataloader):\n        texts, labels = batch\n        texts, labels = texts.to(device), labels.to(device)\n        optimizer.zero_grad()\n        predictions = model(texts, torch.sum(texts != PAD_IDX, dim=1).cpu())\n        loss = criterion(predictions.squeeze(1), labels.float())\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n    return epoch_loss / len(dataloader)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T07:04:25.953843Z","iopub.execute_input":"2024-07-07T07:04:25.954193Z","iopub.status.idle":"2024-07-07T07:04:25.960858Z","shell.execute_reply.started":"2024-07-07T07:04:25.954162Z","shell.execute_reply":"2024-07-07T07:04:25.959949Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(model, dataloader, criterion, device):\n    model.eval()\n    epoch_loss = 0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for batch in tqdm(dataloader):\n            texts, labels = batch\n            texts, labels = texts.to(device), labels.to(device)\n            predictions = model(texts, torch.sum(texts != PAD_IDX, dim=1).cpu())\n            loss = criterion(predictions.squeeze(1), labels.float())\n            epoch_loss += loss.item()\n            predicted = torch.round(torch.sigmoid(predictions.squeeze(1)))\n            correct += (predicted == labels).sum().item()\n            total += labels.size(0)\n    return epoch_loss / len(dataloader), correct / total","metadata":{"execution":{"iopub.status.busy":"2024-07-07T07:04:26.138665Z","iopub.execute_input":"2024-07-07T07:04:26.138982Z","iopub.status.idle":"2024-07-07T07:04:26.146055Z","shell.execute_reply.started":"2024-07-07T07:04:26.138957Z","shell.execute_reply":"2024-07-07T07:04:26.145204Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-07-07T10:27:39.038907Z","iopub.execute_input":"2024-07-07T10:27:39.039260Z","iopub.status.idle":"2024-07-07T10:27:39.093595Z","shell.execute_reply.started":"2024-07-07T10:27:39.039232Z","shell.execute_reply":"2024-07-07T10:27:39.092484Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"optimizer = optim.Adam(model_lstm.parameters())\ncriterion = nn.BCEWithLogitsLoss()\nmodel_lstm = model_lstm.to(device)\ncriterion = criterion.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-07-06T08:12:57.044376Z","iopub.execute_input":"2024-07-06T08:12:57.045028Z","iopub.status.idle":"2024-07-06T08:12:57.053018Z","shell.execute_reply.started":"2024-07-06T08:12:57.044995Z","shell.execute_reply":"2024-07-06T08:12:57.052156Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"NUM_EPOCHS = 5\nfor epoch in range(NUM_EPOCHS):\n    train_loss = train_model(model_lstm, train_dataloader, optimizer, criterion, device)\n    print(f'Epoch {epoch+1}/{NUM_EPOCHS}, Training Loss: {train_loss:.4f}')\n\n    test_loss, test_accuracy = evaluate_model(model_lstm, test_dataloader, criterion, device)\n    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-07-06T08:12:59.437768Z","iopub.execute_input":"2024-07-06T08:12:59.438589Z","iopub.status.idle":"2024-07-06T08:53:43.708780Z","shell.execute_reply.started":"2024-07-06T08:12:59.438555Z","shell.execute_reply":"2024-07-06T08:53:43.707865Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stderr","text":"100%|██████████| 80000/80000 [07:19<00:00, 181.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/5, Training Loss: 0.4916\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 20000/20000 [00:49<00:00, 403.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss: 0.4541, Test Accuracy: 0.7840\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 80000/80000 [07:18<00:00, 182.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/5, Training Loss: 0.4428\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 20000/20000 [00:49<00:00, 405.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss: 0.4494, Test Accuracy: 0.7866\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 80000/80000 [07:19<00:00, 182.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/5, Training Loss: 0.4311\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 20000/20000 [00:49<00:00, 405.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss: 0.4509, Test Accuracy: 0.7880\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 80000/80000 [07:19<00:00, 182.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/5, Training Loss: 0.4255\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 20000/20000 [00:49<00:00, 402.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss: 0.4494, Test Accuracy: 0.7872\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 80000/80000 [07:20<00:00, 181.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/5, Training Loss: 0.4215\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 20000/20000 [00:49<00:00, 405.20it/s]","output_type":"stream"},{"name":"stdout","text":"Test Loss: 0.4515, Test Accuracy: 0.7865\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Other Preproc","metadata":{}},{"cell_type":"code","source":"from nltk.tokenize import word_tokenize","metadata":{"execution":{"iopub.status.busy":"2024-07-07T10:19:12.351184Z","iopub.execute_input":"2024-07-07T10:19:12.351619Z","iopub.status.idle":"2024-07-07T10:19:12.356593Z","shell.execute_reply.started":"2024-07-07T10:19:12.351579Z","shell.execute_reply":"2024-07-07T10:19:12.355494Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def preprocess_text(text):\n    text = text.lower()\n    text = re.sub(text_cleaning_re, ' ', text).strip()\n    text = expand_abbreviations(text)\n    text = \" \".join([word for word in word_tokenize(text)])\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-07-07T10:19:12.516710Z","iopub.execute_input":"2024-07-07T10:19:12.517348Z","iopub.status.idle":"2024-07-07T10:19:12.522145Z","shell.execute_reply.started":"2024-07-07T10:19:12.517317Z","shell.execute_reply":"2024-07-07T10:19:12.521179Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"df['text_prepared'] = df.text.apply(lambda x: preprocess_text(x))","metadata":{"execution":{"iopub.status.busy":"2024-07-07T10:19:13.572479Z","iopub.execute_input":"2024-07-07T10:19:13.572867Z","iopub.status.idle":"2024-07-07T10:24:26.902833Z","shell.execute_reply.started":"2024-07-07T10:19:13.572836Z","shell.execute_reply":"2024-07-07T10:24:26.902022Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"df.text_prepared[19]","metadata":{"execution":{"iopub.status.busy":"2024-07-07T10:24:26.904307Z","iopub.execute_input":"2024-07-07T10:24:26.904601Z","iopub.status.idle":"2024-07-07T10:24:26.910654Z","shell.execute_reply.started":"2024-07-07T10:24:26.904576Z","shell.execute_reply":"2024-07-07T10:24:26.909808Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"'oh dear were you drinking out of the forgotten table drinks'"},"metadata":{}}]},{"cell_type":"code","source":"X = np.array(df['text_prepared'])\ny = np.array(df['sentiment'])","metadata":{"execution":{"iopub.status.busy":"2024-07-07T10:24:26.911926Z","iopub.execute_input":"2024-07-07T10:24:26.912653Z","iopub.status.idle":"2024-07-07T10:24:26.944016Z","shell.execute_reply.started":"2024-07-07T10:24:26.912621Z","shell.execute_reply":"2024-07-07T10:24:26.943089Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                    stratify=y, \n                                                    test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T10:24:26.946058Z","iopub.execute_input":"2024-07-07T10:24:26.946340Z","iopub.status.idle":"2024-07-07T10:24:27.605334Z","shell.execute_reply.started":"2024-07-07T10:24:26.946316Z","shell.execute_reply":"2024-07-07T10:24:27.604557Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"tokenizer = MyTokenizer(10000)\ntokenizer.fit(X_train)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T10:24:27.606402Z","iopub.execute_input":"2024-07-07T10:24:27.606668Z","iopub.status.idle":"2024-07-07T10:24:34.156060Z","shell.execute_reply.started":"2024-07-07T10:24:27.606646Z","shell.execute_reply":"2024-07-07T10:24:34.155266Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"tokenizer.decode(tokenizer.encode('oh dear were you drinking out of the forgotten table drinks'))","metadata":{"execution":{"iopub.status.busy":"2024-07-07T07:03:22.682194Z","iopub.execute_input":"2024-07-07T07:03:22.682577Z","iopub.status.idle":"2024-07-07T07:03:22.690874Z","shell.execute_reply.started":"2024-07-07T07:03:22.682546Z","shell.execute_reply":"2024-07-07T07:03:22.689919Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"'oh dear were you drinking out of the forgotten table drinks'"},"metadata":{}}]},{"cell_type":"code","source":"train_dataset = TextDataset(X_train, y_train, tokenizer)\ntrain_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n\ntest_dataset = TextDataset(X_test, y_test, tokenizer)\ntest_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T07:03:35.116483Z","iopub.execute_input":"2024-07-07T07:03:35.117199Z","iopub.status.idle":"2024-07-07T07:03:35.122309Z","shell.execute_reply.started":"2024-07-07T07:03:35.117163Z","shell.execute_reply":"2024-07-07T07:03:35.121370Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"model_lstm_2 = TextLSTM(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, PAD_IDX)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T07:03:51.577679Z","iopub.execute_input":"2024-07-07T07:03:51.578410Z","iopub.status.idle":"2024-07-07T07:03:51.600076Z","shell.execute_reply.started":"2024-07-07T07:03:51.578378Z","shell.execute_reply":"2024-07-07T07:03:51.599364Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"optimizer_2 = optim.Adam(model_lstm_2.parameters())\ncriterion = nn.BCEWithLogitsLoss()\nmodel_lstm_2 = model_lstm_2.to(device)\ncriterion = criterion.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T07:04:17.682474Z","iopub.execute_input":"2024-07-07T07:04:17.682932Z","iopub.status.idle":"2024-07-07T07:04:18.213474Z","shell.execute_reply.started":"2024-07-07T07:04:17.682900Z","shell.execute_reply":"2024-07-07T07:04:18.212719Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"NUM_EPOCHS = 5\nfor epoch in range(NUM_EPOCHS):\n    train_loss = train_model(model_lstm_2, train_dataloader, optimizer_2, criterion, device)\n    print(f'Epoch {epoch+1}/{NUM_EPOCHS}, Training Loss: {train_loss:.4f}')\n\n    test_loss, test_accuracy = evaluate_model(model_lstm_2, test_dataloader, criterion, device)\n    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-07-07T07:05:32.792915Z","iopub.execute_input":"2024-07-07T07:05:32.793659Z","iopub.status.idle":"2024-07-07T07:49:58.282082Z","shell.execute_reply.started":"2024-07-07T07:05:32.793615Z","shell.execute_reply":"2024-07-07T07:49:58.281166Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"100%|██████████| 80000/80000 [07:59<00:00, 166.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/5, Training Loss: 0.4295\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 20000/20000 [00:53<00:00, 371.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss: 0.3938, Test Accuracy: 0.8207\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 80000/80000 [07:59<00:00, 166.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/5, Training Loss: 0.3796\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 20000/20000 [00:53<00:00, 377.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss: 0.3864, Test Accuracy: 0.8253\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 80000/80000 [07:57<00:00, 167.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/5, Training Loss: 0.3680\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 20000/20000 [00:53<00:00, 376.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss: 0.3886, Test Accuracy: 0.8239\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 80000/80000 [08:02<00:00, 165.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/5, Training Loss: 0.3608\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 20000/20000 [00:53<00:00, 374.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss: 0.3851, Test Accuracy: 0.8263\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 80000/80000 [08:00<00:00, 166.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/5, Training Loss: 0.3561\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 20000/20000 [00:53<00:00, 376.02it/s]","output_type":"stream"},{"name":"stdout","text":"Test Loss: 0.3848, Test Accuracy: 0.8268\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## BERT","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained('bert-base-cased')","metadata":{"execution":{"iopub.status.busy":"2024-07-07T10:24:34.157108Z","iopub.execute_input":"2024-07-07T10:24:34.157395Z","iopub.status.idle":"2024-07-07T10:24:38.011467Z","shell.execute_reply.started":"2024-07-07T10:24:34.157370Z","shell.execute_reply":"2024-07-07T10:24:38.010716Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47d066ae92ce412194160c1ac9dded3f"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bf9db1db60c4fe9a1b7aba540bddbfa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af307aa0c6d54795bf660dc065895daa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89eecc6d17d44bb2a0b9c30857ea4988"}},"metadata":{}}]},{"cell_type":"code","source":"tokenizer('oh dear were you drinking out of the forgotten table drinks')","metadata":{"execution":{"iopub.status.busy":"2024-07-07T10:24:38.012913Z","iopub.execute_input":"2024-07-07T10:24:38.013492Z","iopub.status.idle":"2024-07-07T10:24:38.021789Z","shell.execute_reply.started":"2024-07-07T10:24:38.013454Z","shell.execute_reply":"2024-07-07T10:24:38.020947Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [101, 9294, 7059, 1127, 1128, 5464, 1149, 1104, 1103, 6278, 1952, 8898, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}]},{"cell_type":"code","source":"class BertDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len=25):\n        super(BertDataset, self).__init__()\n        \n        self.texts = texts\n        self.tokenizer = tokenizer\n        self.target = labels\n        self.max_length = max_len\n        \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, index):\n        \n        text1 = self.texts[index]\n        \n        inputs = self.tokenizer.encode_plus(\n            text1 ,\n            None,\n            pad_to_max_length=True,\n            add_special_tokens=True,\n            return_attention_mask=True,\n            max_length=self.max_length,\n        )\n        ids = inputs[\"input_ids\"]\n        token_type_ids = inputs[\"token_type_ids\"]\n        mask = inputs[\"attention_mask\"]\n\n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long),\n            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n            'target': torch.tensor(self.target[index], dtype=torch.long)\n            }\n\nbert_dataset_train = BertDataset(X_train, y_train, tokenizer, max_len=50)\nbert_dataset_test = BertDataset(X_test, y_test, tokenizer, max_len=50)\n\nbert_dataloader_train = DataLoader(dataset=bert_dataset_train,batch_size=16)\nbert_dataloader_test = DataLoader(dataset=bert_dataset_test,batch_size=16)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-07T10:24:38.022975Z","iopub.execute_input":"2024-07-07T10:24:38.023231Z","iopub.status.idle":"2024-07-07T10:24:38.034874Z","shell.execute_reply.started":"2024-07-07T10:24:38.023208Z","shell.execute_reply":"2024-07-07T10:24:38.033962Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification","metadata":{"execution":{"iopub.status.busy":"2024-07-07T10:24:38.035872Z","iopub.execute_input":"2024-07-07T10:24:38.036119Z","iopub.status.idle":"2024-07-07T10:24:38.058460Z","shell.execute_reply.started":"2024-07-07T10:24:38.036097Z","shell.execute_reply":"2024-07-07T10:24:38.057813Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"class BERT(nn.Module):\n    def __init__(self):\n        super(BERT, self).__init__()\n        self.bert_model = AutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased\")\n#         self.distilbert = bert_model.distilbert\n#         self.pre_classifier = bert_model.pre_classifier\n#         self.dropout = bert_model.dropout\n        self.bert_model.classifier = nn.Linear(768, 1)\n        \n    def forward(self,ids,mask,token_type_ids):\n        out = self.bert_model(ids, attention_mask=mask, return_dict=False)        \n        return out\n    \nmodel_bert = BERT()\nmodel_bert = model_bert.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T12:36:51.327614Z","iopub.execute_input":"2024-07-07T12:36:51.328323Z","iopub.status.idle":"2024-07-07T12:36:51.745822Z","shell.execute_reply.started":"2024-07-07T12:36:51.328287Z","shell.execute_reply":"2024-07-07T12:36:51.745046Z"},"trusted":true},"execution_count":115,"outputs":[{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"model_bert","metadata":{"execution":{"iopub.status.busy":"2024-07-07T12:36:51.747567Z","iopub.execute_input":"2024-07-07T12:36:51.748015Z","iopub.status.idle":"2024-07-07T12:36:51.754703Z","shell.execute_reply.started":"2024-07-07T12:36:51.747983Z","shell.execute_reply":"2024-07-07T12:36:51.753808Z"},"trusted":true},"execution_count":116,"outputs":[{"execution_count":116,"output_type":"execute_result","data":{"text/plain":"BERT(\n  (bert_model): DistilBertForSequenceClassification(\n    (distilbert): DistilBertModel(\n      (embeddings): Embeddings(\n        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n        (position_embeddings): Embedding(512, 768)\n        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (transformer): Transformer(\n        (layer): ModuleList(\n          (0-5): 6 x TransformerBlock(\n            (attention): MultiHeadSelfAttention(\n              (dropout): Dropout(p=0.1, inplace=False)\n              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (ffn): FFN(\n              (dropout): Dropout(p=0.1, inplace=False)\n              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n              (activation): GELUActivation()\n            )\n            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          )\n        )\n      )\n    )\n    (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n    (classifier): Linear(in_features=768, out_features=1, bias=True)\n    (dropout): Dropout(p=0.2, inplace=False)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"for param in model_bert.bert_model.distilbert.parameters():\n    param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2024-07-07T12:36:52.525423Z","iopub.execute_input":"2024-07-07T12:36:52.525819Z","iopub.status.idle":"2024-07-07T12:36:52.530806Z","shell.execute_reply.started":"2024-07-07T12:36:52.525765Z","shell.execute_reply":"2024-07-07T12:36:52.529970Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model_bert(model, dataloader, optimizer, criterion, device):\n    model.train()\n    epoch_loss = 0\n    for batch in tqdm(dataloader):\n        ids = batch['ids']\n        token_type_ids = batch['token_type_ids']\n        mask = batch['mask']\n        labels = batch['target']\n        ids, token_type_ids, mask, labels = ids.to(device), token_type_ids.to(device), mask.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        \n        predictions = model(ids=ids,\n                            mask=mask,\n                            token_type_ids=token_type_ids)\n        \n        loss = criterion(predictions[0].squeeze(1), labels.float())\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n    return epoch_loss / len(dataloader)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T12:36:22.919276Z","iopub.execute_input":"2024-07-07T12:36:22.920016Z","iopub.status.idle":"2024-07-07T12:36:22.927359Z","shell.execute_reply.started":"2024-07-07T12:36:22.919983Z","shell.execute_reply":"2024-07-07T12:36:22.926334Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"def evaluate_model_bert(model, dataloader, criterion, device):\n    model.eval()\n    epoch_loss = 0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for batch in tqdm(dataloader):\n            ids = batch['ids']\n            token_type_ids = batch['token_type_ids']\n            mask = batch['mask']\n            labels = batch['target']\n            ids, token_type_ids, mask, labels = ids.to(device), token_type_ids.to(device), mask.to(device), labels.to(device)\n            predictions = model(ids=ids,\n                                mask=mask,\n                                token_type_ids=token_type_ids)\n            loss = criterion(predictions[0].squeeze(1), labels.float())\n            epoch_loss += loss.item()\n            predicted = torch.round(torch.sigmoid(predictions[0].squeeze(1)))\n            correct += (predicted == labels).sum().item()\n            total += labels.size(0)\n    return epoch_loss / len(dataloader), correct / total","metadata":{"execution":{"iopub.status.busy":"2024-07-07T12:36:23.198839Z","iopub.execute_input":"2024-07-07T12:36:23.199578Z","iopub.status.idle":"2024-07-07T12:36:23.207565Z","shell.execute_reply.started":"2024-07-07T12:36:23.199549Z","shell.execute_reply":"2024-07-07T12:36:23.206728Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"code","source":"criterion = nn.BCEWithLogitsLoss()\noptimizer_bert= optim.Adam(model_bert.parameters())","metadata":{"execution":{"iopub.status.busy":"2024-07-07T12:36:59.685397Z","iopub.execute_input":"2024-07-07T12:36:59.686047Z","iopub.status.idle":"2024-07-07T12:36:59.691354Z","shell.execute_reply.started":"2024-07-07T12:36:59.686013Z","shell.execute_reply":"2024-07-07T12:36:59.690316Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_EPOCHS = 3\nfor epoch in range(NUM_EPOCHS):\n    train_loss = train_model_bert(model_bert, bert_dataloader_train, optimizer_bert, criterion, device)\n    print(f'Epoch {epoch+1}/{NUM_EPOCHS}, Training Loss: {train_loss:.4f}')\n\n    test_loss, test_accuracy = evaluate_model_bert(model_bert, bert_dataloader_test, criterion, device)\n    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-07-07T12:37:00.653411Z","iopub.execute_input":"2024-07-07T12:37:00.653764Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"100%|██████████| 80000/80000 [33:00<00:00, 40.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/3, Training Loss: 0.6518\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 20000/20000 [08:04<00:00, 41.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss: 0.6291, Test Accuracy: 0.6419\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 80000/80000 [32:59<00:00, 40.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/3, Training Loss: 0.6383\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 20000/20000 [08:04<00:00, 41.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss: 0.6238, Test Accuracy: 0.6409\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 80000/80000 [32:59<00:00, 40.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/3, Training Loss: 0.6316\n","output_type":"stream"},{"name":"stderr","text":" 85%|████████▌ | 17055/20000 [06:53<01:11, 41.04it/s]","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}